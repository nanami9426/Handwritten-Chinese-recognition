{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac38639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "data_dir = pathlib.Path('../data_for_test/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f77993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ead2dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data_for_test\\test\\哀\\0.jpg\n",
      "<class 'pathlib.WindowsPath'>\n"
     ]
    }
   ],
   "source": [
    "for i in data_dir.rglob('*'):\n",
    "    if i.is_file():\n",
    "#         print(i,i.parent.name)\n",
    "        print(i)\n",
    "        print(type(i))\n",
    "        img = PIL.Image.open(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31bae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哀\n",
      "哎\n",
      "唉\n",
      "啊\n",
      "埃\n",
      "挨\n",
      "皑\n",
      "阿\n"
     ]
    }
   ],
   "source": [
    "for i in data_dir.glob('*'):\n",
    "\n",
    "#         print(i,i.parent.name)\n",
    "    print(i.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "492fefd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABTACcBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf6K8iTxJqGl/EyO1u7i4ZTKIJwz5RweFKr2AznivXaKKztS1vTNITdf3kVuMbvnPOPXFeC+L/E8Oo+OW1bTULrEY9hc4DFR1rX03T/AB14sjjd7i5jtSxYNLMdg59zk17FolnNpui2lncSmeWGMIz88n2z2HT8K878Y+I/E832yysNPnhi3GFdsTFyMcEnp8wycfzxmuZ074ZeI9YC3OpzraxhME3BJZQBkcemK6u1tPh/4LXbczw3t6hG5mUOwPbA6Cu30HxDo+u23/EquY3WMbfKA2lQOPu+nStqiua03xLp/iS6v9LtmlUohUyD5SQcjIzyD36Vxuv+B/Dmg6Sb2/nlkulOQitgSk8bcdvr7U74Y+GLq31G51yaNra3cNHBBzzz155wOa9Vorx7U9LHgjxLLc291J9nnTzYIx1LZPBJPYgHJ4NYy65Yz60t1qMc+q3ZdfKh3kqG/Hr0Fe4WExubCCZoDAXQExH+D2+lWqK83+LE9mdNtrV08y8YMY/mxtU4zn2JA/Kp/A3g6zsLMaleadDFOx3xhxnYuPvHPQ9f0NdvBfWl27pbXcEzpw6xyBiv1weOtWqYzBFLMQFAySTwBXjGqana6l4ivdVmnZo4APLiddw3duPQVBrfiPXtUVJLqSWG3Z8RoECk5HGB1P1rvPh94eOmaZ9tnEq3Fwv3JOCi5P8APg/THqa7WvOvF/jBZZ10SwEgaWTZJMpXscELz+v+Ty3jfSG8Gva3NiS0cirklskOCc8eh9e9afw8utO8UatcXupqH1CPDRQs3yKPVVz7dMV63RXiV9qVnb/ES+nuLaNooJHbys/6xgT1zwM5yfTmuy03QJvFF2+seI4FMTRmO3tCvCqf4v14/wA58q8RaTdeB/GIktshEkWaBvVc8fyr3bwvr0XiLQ7e/Ro/MZcSojZ2t3rarnJfBejS60dVaBhcFizgN8rk9cjH8q6OsLxH4bs/Eumva3A2y7T5cygblP5dM9RXjUB8RfDXWgZEf7KXIKjlJl/zivU9E+IWiatCga4MNyYwzxsh698YzXX0UVVvrC11K1e3vYEnhPVHGRWPpvg/w/p19JNa6ZEki8BiWbAI56k1/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=39x83>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2903010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001865dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be02f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWVocab:\n",
    "    def __init__(self,data_dir):\n",
    "        self.lables = []\n",
    "        self.tlables = [] # 独热编码后的标签 type: torch.Tensor\n",
    "        self.char_dict = {}\n",
    "        self.initialize_dict(data_dir)\n",
    "    def initialize_dict(self,path):\n",
    "        data_dir = pathlib.Path(path)\n",
    "        for i in data_dir.glob('*'):\n",
    "            if i not in self.lables:\n",
    "                self.lables.append(i.name)\n",
    "        for idx,c in enumerate(self.lables):\n",
    "            self.char_dict[c] = idx\n",
    "        self.tlables = F.one_hot(torch.tensor([self.char_dict[x] for x in self.lables]))\n",
    "        print(f\"dict initialized successfully,there's {len(self.char_dict)} lables in the dict.\")\n",
    "        \n",
    "    def __getitem__(self,c):\n",
    "        if isinstance(c,list):\n",
    "            return [self.tlables[self.char_dict[x]] for x in c]\n",
    "        return self.tlables[self.char_dict[c]]\n",
    "        \n",
    "    def lable2char(self,idx):\n",
    "        if isinstance(idx,torch.Tensor):\n",
    "            return self.lables[idx.argmax().item()]\n",
    "        return self.lables[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f49effad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict initialized successfully,there's 8 lables in the dict.\n"
     ]
    }
   ],
   "source": [
    "voc_test = HWVocab('../data_for_test/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43db71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(voc_test['哀'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234762e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'哀'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_test.lable2char(voc_test['哀'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a98a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ae70de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWDataset(Dataset):\n",
    "    # Hand Writting Dataset\n",
    "    def __init__(self,data_dir):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((48,48)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.to_img = transforms.ToPILImage()\n",
    "        self.data_dir = data_dir\n",
    "        self.vocab = HWVocab(data_dir)\n",
    "        self.data_list = self.get_data_list()\n",
    "    def get_data_list(self):\n",
    "        data_list = []\n",
    "        data_dir = pathlib.Path(self.data_dir)\n",
    "        for file in data_dir.rglob('*'):\n",
    "            if file.is_file():\n",
    "                lable = self.vocab[file.parent.name]\n",
    "                # img = PIL.Image.open(file)\n",
    "                # feature = self.transform(img)\n",
    "                data_list.append((file,lable))\n",
    "        print(f\"lenth of dataset is : {len(data_list)}\")\n",
    "        return data_list\n",
    "    \n",
    "    def get_real_feature(self,file):\n",
    "        img = PIL.Image.open(file)\n",
    "        feature = self.transform(img)\n",
    "        return feature\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.get_real_feature(self.data_list[idx][0]),self.data_list[idx][1]\n",
    "    \n",
    "    def get_img(self,idx):\n",
    "        item = self.data_list[idx]\n",
    "        img = self.to_img(self.get_real_feature(item[0]))\n",
    "        return (self.vocab.lable2char(item[1]),img)\n",
    "    \n",
    "    def __del__(self):\n",
    "        del self.vocab\n",
    "        print('delete instance HWDataset,HWVocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6980447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict initialized successfully,there's 8 lables in the dict.\n",
      "lenth of dataset is : 477\n"
     ]
    }
   ],
   "source": [
    "test = HWDataset(data_dir='../data_for_test/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b47be76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.9961, 0.9922, 0.9882,  ..., 0.5922, 0.6824, 0.7255],\n",
       "          [1.0000, 0.9961, 1.0000,  ..., 0.4510, 0.6078, 0.7647],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.8235, 0.9020, 0.9765]]]),\n",
       " tensor([1, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfbc1749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAwADABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf64rxtr1nbJaW9vdF78XKYjgbcwH8RIHtWoNb1e8QGw0OQKRw93IIwfw5NP83xOcH7Npq+o8xj/SpYdQ1aK7jivdOTy5G2iSCTdj3II6Vs1Wv7Y3lo9uJWi34BZeuM8isZ9M8P+FYpdWNqsRGA0oXc2Scfrmqc/jBtQu0sdDWIzOMiW6yiDHUAdSap3t7rdtcW8MGq/bdQlkwYIYlESDvk9RXcpnYN2M45xS0VheK5rBNIMd7O8ZdwYljAZ3cHIAHeud0bRF1y7jl1KZlNlnZbKNjDPBLY9cdq6zTH0tJZrTT/ACg0GBIEHQn3q5c3ltZxGS4njiQdS7YotLuC+tluLaQSRN91l6GsHxF4ystEJtoR9q1Aj5beP+H3Y9hXPWsWqMsnifUPKkuIkLJ5/EVunfaByx964zTvEXjPVH1afTLQzSTsokmjHMa84CitjRvE+q6BpsVvdaY1lG0nlyzyLmR5D7HAx713en+GFuJDe6wftM7ncImOUT8O5ro44khjWONAiLwFUYArA0/wXpGn3014I5JppWLEzPu5+lZ3jKZ7+5sPDNqdrXjhpyP4Yxz/AE/So7/w/e+Hr3+1/D8kSxCNVns5eFkUDqD2Ncr4ivdU8S6fPNe6JfQqqA2oiTeoIPLE12Gl+PdMOm2ouku4ZREofdbNjOBnBrQi8ZaVcTrDb/aZZGYKAsDd/qK6GuD1a6GmfEZL64huJIvsW2IRRltzE4wK2ba3v9elW41CJrWyHMdqT8z+7/4V0SqqqFUAADAApCiEYKrj6UBFByFA/Cv/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=48x48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get_img(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38c57ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('哀', <PIL.Image.Image image mode=L size=48x48>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get_img(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce67f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [0.9961, 0.9922, 0.9882,  ..., 0.5922, 0.6824, 0.7255],\n",
      "         [1.0000, 0.9961, 1.0000,  ..., 0.4510, 0.6078, 0.7647],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 0.8235, 0.9020, 0.9765]]]), tensor([1, 0, 0, 0, 0, 0, 0, 0]))\n",
      "torch.Size([1, 48, 48])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for i in test:\n",
    "    print(i)\n",
    "    print(i[0].shape)\n",
    "    print(i[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7b1bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69d7c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset=test,batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a64c3d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.8667, 0.9647, 0.9961],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.5804, 0.6745, 0.8627],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.6039, 0.6235, 0.7922]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.8039, 0.9255, 0.9882],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.5529, 0.6588, 0.8510],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.7098, 0.7020, 0.7608]]]])\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in dl:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bca3e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79e0fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\condaenvs\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\condaenvs\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet101 = torchvision.models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "676bf1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=2048, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet101.children())[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4a21e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c0fcf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1000]), tensor(741))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = torch.randn([2,3,48,48])\n",
    "resnet101.eval()\n",
    "o = resnet101(test_data)\n",
    "o.shape,o[0][:].argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7909f8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet101.children())[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c892887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import ResNet101_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1096da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HWNet(nn.Module):\n",
    "    def __init__(self,num_lables):\n",
    "        super().__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels=1,out_channels=3,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.num_labels = num_lables\n",
    "        resnet101 = torchvision.models.resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
    "        self.res101 = nn.Sequential(*list(resnet101.children())[:-1])\n",
    "        self.dense = nn.Linear(in_features=2048,out_features=self.num_labels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.res101(x).reshape(len(x),-1)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "851471c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = HWNet(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bee3e2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       "   (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (4): Sequential(\n",
       "     (0): Bottleneck(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Bottleneck(\n",
       "       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (2): Bottleneck(\n",
       "       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (5): Sequential(\n",
       "     (0): Bottleneck(\n",
       "       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Bottleneck(\n",
       "       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (2): Bottleneck(\n",
       "       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (3): Bottleneck(\n",
       "       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (6): Sequential(\n",
       "     (0): Bottleneck(\n",
       "       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (2): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (3): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (4): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (5): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (6): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (7): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (8): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (9): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (10): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (11): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (12): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (13): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (14): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (15): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (16): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (17): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (18): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (19): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (20): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (21): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (22): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (7): Sequential(\n",
       "     (0): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Bottleneck(\n",
       "       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (2): Bottleneck(\n",
       "       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       " ),\n",
       " Linear(in_features=2048, out_features=8, bias=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mynet.children())[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cec73c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.7922, 0.9255, 0.9961],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.6902, 0.7922, 0.9412],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.7843, 0.6745, 0.7255]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 0.9922, 0.9961, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9922, 0.9961, 0.9961],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.8745, 0.9569, 0.9922],\n",
      "          ...,\n",
      "          [0.9922, 0.9922, 0.9961,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.9882, 0.9961, 0.9882,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.9882, 0.9922, 0.9882,  ..., 1.0000, 1.0000, 1.0000]]]])\n",
      "tensor([[-0.2056, -0.1036, -0.0716, -0.0065, -0.0982,  0.0319,  0.0019, -0.0800],\n",
      "        [ 0.0673,  0.0286, -0.0806,  0.0428,  0.0266,  0.0162,  0.0102, -0.0143]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in dl:\n",
    "    print(x)\n",
    "    print(mynet(x))\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9c301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea91c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5e722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
